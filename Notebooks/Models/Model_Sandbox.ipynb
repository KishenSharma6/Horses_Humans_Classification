{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d778183-abda-4d03-b931-c1753afe157c",
   "metadata": {},
   "source": [
    "Import Libraries/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e11bac-827e-4653-9302-9f643dee2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "\n",
    "#Import image loaders\n",
    "os.chdir(\"../../src/\")\n",
    "from load_data import preview_images, load_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bf8754b-adbd-4c80-b9ce-8e556e9735b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Horse Data: (500, 300, 300, 4) \n",
      "Test Horse Data: (128, 300, 300, 4)\n",
      "\n",
      "Training Human Data: (527, 300, 300, 4) \n",
      "Test Human Data: (128, 300, 300, 4)\n"
     ]
    }
   ],
   "source": [
    "#Import and preview image data\n",
    "train_path= \"../Data/train/\"\n",
    "horse_train= load_images(train_path + \"horses/\")\n",
    "human_train= load_images(train_path + \"humans/\")\n",
    "\n",
    "val_path= \"../Data/validation/\"\n",
    "horse_test= load_images(val_path + \"horses/\")\n",
    "human_test= load_images(val_path + \"humans/\")\n",
    "\n",
    "#Sanity Check\n",
    "print(\"Training Horse Data: %s \\nTest Horse Data: %s\\n\" % (horse_train.shape, horse_test.shape))\n",
    "print(\"Training Human Data: %s \\nTest Human Data: %s\" % (human_train.shape, human_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ca338-5399-42eb-afc1-606c57a7d3d7",
   "metadata": {},
   "source": [
    "Preprocess **Training** Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe10cfa-3bf8-4def-8a91-6fb40675256b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1027, 4, 300, 300])\n",
      "torch.Size([1027, 1])\n"
     ]
    }
   ],
   "source": [
    "#Assign labels: 1= human, 0 = horse\n",
    "y_train_human= np.full((len(human_train),1), 1)\n",
    "y_train_horse= np.full((len(horse_train),1), 0)\n",
    "\n",
    "#Concatenate Training data\n",
    "X= np.concatenate((horse_train, human_train), axis=0)\n",
    "y= np.concatenate((y_train_horse, y_train_human), axis= 0)\n",
    "\n",
    "#Zero-center data\n",
    "training_mean= X.mean()\n",
    "training_std= X.std()\n",
    "X= (X - training_mean)/training_std\n",
    "\n",
    "#Shuffle, reshape and convert to tensors\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train= shuffle(X, y)\n",
    "\n",
    "X_train= X_train.reshape((-1, 4, 300, 300))\n",
    "\n",
    "X_train= torch.from_numpy(X_train)\n",
    "y_train= torch.from_numpy(y_train)\n",
    "\n",
    "#Sanity Check\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "#Wrap tensors into Dataset \n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7287ee-1f85-4bff-a57b-c41589bcdc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: torch.Size([256, 4, 300, 300]) \n",
      "Test label shape: torch.Size([256, 1])\n"
     ]
    }
   ],
   "source": [
    "#Preprocess Test Data\n",
    "y_test_human= np.full((len(human_test),1), 1)\n",
    "y_test_horse= np.full((len(horse_test),1), 0)\n",
    "\n",
    "#Concatenate validation set\n",
    "X= np.concatenate((horse_test, human_test), axis=0)\n",
    "y= np.concatenate((y_test_horse, y_test_human), axis= 0)\n",
    "\n",
    "#Zero-Center data\n",
    "X= (X- training_mean)/training_std\n",
    "\n",
    "#Shuffle, reshape, and convert test data to tensors\n",
    "X_test, y_test= shuffle(X, y)\n",
    "\n",
    "X_test= X_test.reshape((-1, 4, 300, 300))\n",
    "\n",
    "X_test= torch.from_numpy(X_test)\n",
    "y_test= torch.from_numpy(y_test)\n",
    "\n",
    "#Sanity Check\n",
    "print(\"Test data shape: %s \\nTest label shape: %s\" % (X_test.shape, y_test.shape))\n",
    "\n",
    "#Wrap tensors into Dataset \n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a076f7c3-1ccd-4a50-af7b-25ae1a07c4dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192f8c3c-4b86-432a-bf51-222b970e8381",
   "metadata": {},
   "source": [
    "Base ANN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85a65ffd-3144-43fc-a9ce-73c3242740e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseNeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=360000, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Use base model from early computer vision\n",
    "from models import BaseNeuralNetwork, train_loop, test_loop\n",
    "\n",
    "device= \"cpu\"\n",
    "base_model= BaseNeuralNetwork().to(device)\n",
    "print(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9da65b-1f9f-428c-b28f-bcd6ff2e8031",
   "metadata": {},
   "source": [
    "Base ANN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cf8cc48-9b61-40ff-a734-bdf84dedb5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 4, 300, 300])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([256, 4, 300, 300])\n",
      "torch.Size([256, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "#Set up loss function, optimizer and batch\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(base_model.parameters(),\n",
    "                      lr= 10 ** -3,\n",
    "                       momentum= .9)\n",
    "\n",
    "batch_size= 64\n",
    "\n",
    "#Create DataLoader iterable\n",
    "train_dataloader= DataLoader(train_dataset, batch_size= batch_size, shuffle= False, drop_last= True)\n",
    "test_dataloader= DataLoader(test_dataset, batch_size= len(test_dataset), shuffle= False)\n",
    "\n",
    "#Sanity Check\n",
    "for x, y in train_dataloader:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break          \n",
    "#Sanity Check\n",
    "for x, y in test_dataloader:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b34d409-fdd4-4bf3-b4b4-dd3503f72b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "----------------------------\n",
      "loss: 0.697754  [    0/ 1027]\n",
      "loss: 0.675377  [   64/ 1027]\n",
      "loss: 0.623814  [  128/ 1027]\n",
      "loss: 0.626251  [  192/ 1027]\n",
      "loss: 0.601297  [  256/ 1027]\n",
      "loss: 0.715795  [  320/ 1027]\n",
      "loss: 0.516409  [  384/ 1027]\n",
      "loss: 0.501635  [  448/ 1027]\n",
      "loss: 0.439040  [  512/ 1027]\n",
      "loss: 0.446919  [  576/ 1027]\n",
      "loss: 0.432253  [  640/ 1027]\n",
      "loss: 0.372604  [  704/ 1027]\n",
      "loss: 0.354605  [  768/ 1027]\n",
      "loss: 0.376940  [  832/ 1027]\n",
      "loss: 0.320026  [  896/ 1027]\n",
      "loss: 0.434664  [  960/ 1027]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 1.006387 \n",
      "\n",
      "Epoch 2:\n",
      "----------------------------\n",
      "loss: 0.366628  [    0/ 1027]\n",
      "loss: 0.289138  [   64/ 1027]\n",
      "loss: 0.206712  [  128/ 1027]\n",
      "loss: 0.329080  [  192/ 1027]\n",
      "loss: 0.272741  [  256/ 1027]\n",
      "loss: 0.402812  [  320/ 1027]\n",
      "loss: 0.342310  [  384/ 1027]\n",
      "loss: 0.222391  [  448/ 1027]\n",
      "loss: 0.254685  [  512/ 1027]\n",
      "loss: 0.254607  [  576/ 1027]\n",
      "loss: 0.211176  [  640/ 1027]\n",
      "loss: 0.248827  [  704/ 1027]\n",
      "loss: 0.180324  [  768/ 1027]\n",
      "loss: 0.213989  [  832/ 1027]\n",
      "loss: 0.204812  [  896/ 1027]\n",
      "loss: 0.160941  [  960/ 1027]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 1.034095 \n",
      "\n",
      "Epoch 3:\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "for e in range(epochs):\n",
    "    print(f\"Epoch {e + 1}:\\n----------------------------\")\n",
    "    train_loop(train_dataloader, base_model, criterion, optimizer)\n",
    "    test_loop(test_dataloader, base_model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64386f1c-988e-4018-a07d-f8d5f08e5dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec38258-d3f2-4035-8c2a-dc28c66aa61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= base_model\n",
    "size= len(test_dataloader.dataset)\n",
    "num_batches= len(test_dataloader)\n",
    "test_loss, correct = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "        for (X, y) in test_dataloader:\n",
    "            preds= model(X.float())\n",
    "\n",
    "            test_loss += criterion(preds, y.flatten()).item()\n",
    "            correct += (preds.argmax(1) == y).type(torch.float).sum().item()\n",
    "            print(correct)\n",
    "            print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc026a-2b6b-4886-aa9a-18f7fbf864c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
