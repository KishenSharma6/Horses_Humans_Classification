{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d778183-abda-4d03-b931-c1753afe157c",
   "metadata": {},
   "source": [
    "Import Libraries/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e11bac-827e-4653-9302-9f643dee2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "\n",
    "#Import image loaders\n",
    "os.chdir(\"../../src/\")\n",
    "from load_data import preview_images, load_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bf8754b-adbd-4c80-b9ce-8e556e9735b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Horse Data: (500, 300, 300, 4) \n",
      "Test Horse Data: (128, 300, 300, 4)\n",
      "\n",
      "Training Human Data: (527, 300, 300, 4) \n",
      "Test Human Data: (128, 300, 300, 4)\n"
     ]
    }
   ],
   "source": [
    "#Import and preview image data\n",
    "train_path= \"../Data/train/\"\n",
    "horse_train= load_images(train_path + \"horses/\")\n",
    "human_train= load_images(train_path + \"humans/\")\n",
    "\n",
    "val_path= \"../Data/validation/\"\n",
    "horse_test= load_images(val_path + \"horses/\")\n",
    "human_test= load_images(val_path + \"humans/\")\n",
    "\n",
    "#Sanity Check\n",
    "print(\"Training Horse Data: %s \\nTest Horse Data: %s\\n\" % (horse_train.shape, horse_test.shape))\n",
    "print(\"Training Human Data: %s \\nTest Human Data: %s\" % (human_train.shape, human_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ca338-5399-42eb-afc1-606c57a7d3d7",
   "metadata": {},
   "source": [
    "Preprocess **Training** Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe10cfa-3bf8-4def-8a91-6fb40675256b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1027, 4, 300, 300])\n",
      "torch.Size([1027, 1])\n"
     ]
    }
   ],
   "source": [
    "#Assign labels: 1= human, 0 = horse\n",
    "y_train_human= np.full((len(human_train),1), 1)\n",
    "y_train_horse= np.full((len(horse_train),1), 0)\n",
    "\n",
    "#Concatenate Training data\n",
    "X= np.concatenate((horse_train, human_train), axis=0)\n",
    "y= np.concatenate((y_train_horse, y_train_human), axis= 0)\n",
    "\n",
    "#Zero-center data\n",
    "training_mean= X.mean()\n",
    "training_std= X.std()\n",
    "X= (X - training_mean)/training_std\n",
    "\n",
    "#Shuffle, reshape and convert to tensors\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train= shuffle(X, y)\n",
    "\n",
    "X_train= X_train.reshape((-1, 4, 300, 300))\n",
    "\n",
    "X_train= torch.from_numpy(X_train)\n",
    "y_train= torch.from_numpy(y_train)\n",
    "\n",
    "#Sanity Check\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "#Wrap tensors into Dataset \n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7287ee-1f85-4bff-a57b-c41589bcdc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: torch.Size([256, 4, 300, 300]) \n",
      "Test label shape: torch.Size([256, 1])\n"
     ]
    }
   ],
   "source": [
    "#Preprocess Test Data\n",
    "y_test_human= np.full((len(human_test),1), 1)\n",
    "y_test_horse= np.full((len(horse_test),1), 0)\n",
    "\n",
    "#Concatenate validation set\n",
    "X= np.concatenate((horse_test, human_test), axis=0)\n",
    "y= np.concatenate((y_test_horse, y_test_human), axis= 0)\n",
    "\n",
    "#Zero-Center data\n",
    "X= (X- training_mean)/training_std\n",
    "\n",
    "#Shuffle, reshape, and convert test data to tensors\n",
    "X_test, y_test= shuffle(X, y)\n",
    "\n",
    "X_test= X_test.reshape((-1, 4, 300, 300))\n",
    "\n",
    "X_test= torch.from_numpy(X_test)\n",
    "y_test= torch.from_numpy(y_test)\n",
    "\n",
    "#Sanity Check\n",
    "print(\"Test data shape: %s \\nTest label shape: %s\" % (X_test.shape, y_test.shape))\n",
    "\n",
    "#Wrap tensors into Dataset \n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a076f7c3-1ccd-4a50-af7b-25ae1a07c4dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192f8c3c-4b86-432a-bf51-222b970e8381",
   "metadata": {},
   "source": [
    "Base ANN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85a65ffd-3144-43fc-a9ce-73c3242740e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseNeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=360000, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Use base model from early computer vision\n",
    "from models import BaseNeuralNetwork, train_loop\n",
    "\n",
    "device= \"cpu\"\n",
    "base_model= BaseNeuralNetwork().to(device)\n",
    "print(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9da65b-1f9f-428c-b28f-bcd6ff2e8031",
   "metadata": {},
   "source": [
    "Base ANN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cf8cc48-9b61-40ff-a734-bdf84dedb5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 4, 300, 300])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([256, 4, 300, 300])\n",
      "torch.Size([256, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "#Set up loss function, optimizer and batch\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(base_model.parameters(),\n",
    "                      lr= 10 ** -3,\n",
    "                       momentum= .9)\n",
    "\n",
    "batch_size= 64\n",
    "\n",
    "#Create DataLoader iterable\n",
    "train_dataloader= DataLoader(train_dataset, batch_size= batch_size, shuffle= False)\n",
    "test_dataloader= DataLoader(test_dataset, batch_size= len(test_dataset), shuffle= False)\n",
    "\n",
    "#Sanity Check\n",
    "for x, y in train_dataloader:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break          \n",
    "#Sanity Check\n",
    "for x, y in test_dataloader:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a1b5b2b-23bf-4509-af35-61ff89d4dc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.692595  [   64/ 1027]\n",
      "loss: 0.657384  [  128/ 1027]\n",
      "loss: 0.596722  [  192/ 1027]\n",
      "loss: 0.535421  [  256/ 1027]\n",
      "loss: 0.566393  [  320/ 1027]\n",
      "loss: 0.510413  [  384/ 1027]\n",
      "loss: 0.474450  [  448/ 1027]\n",
      "loss: 0.380675  [  512/ 1027]\n",
      "loss: 0.411957  [  576/ 1027]\n",
      "loss: 0.337791  [  640/ 1027]\n",
      "loss: 0.415704  [  704/ 1027]\n",
      "loss: 0.377260  [  768/ 1027]\n",
      "loss: 0.391146  [  832/ 1027]\n",
      "loss: 0.261502  [  896/ 1027]\n",
      "loss: 0.293247  [  960/ 1027]\n",
      "loss: 0.287931  [ 1024/ 1027]\n",
      "loss: 0.344794  [   51/ 1027]\n"
     ]
    }
   ],
   "source": [
    "train_loop(train_dataloader, base_model, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585a5310-72ad-44a3-9326-05a661173680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "208f0737-f79a-42da-9097-84ee1bafd62c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yv/nkm_y3rj0bj50pcbjh23kfd80000gn/T/ipykernel_3032/3957423419.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aba90ad-c06d-418d-b63b-ec0bbd4612a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c3b7b5-36f8-4853-8157-482d50c03877",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch, (X, y) in enumerate(train_dataloader):\n",
    "    print(batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d1af89-5ad3-46bc-8125-3c1d787e3425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Loop\n",
    "epochs = 5\n",
    "\n",
    "base_model.train()\n",
    "for e in range(epochs):\n",
    "    print(\"-----------------------\")\n",
    "    print(f\"Epoch {e + 1} Results\\n-----------------------\")\n",
    "    \n",
    "    #Training Loop\n",
    "    size= len(train_dataloader.dataset)\n",
    "        #compute predictions and loss\n",
    "    for batch, (X,y) in enumerate(train_dataloader):\n",
    "        \n",
    "        #Make predictions and compute loss\n",
    "        pred= base_model(X.float())\n",
    "        loss= criterion(pred, y.flatten())\n",
    "        \n",
    "        #Always zero gradients for each batch\n",
    "        optimizer.zero_grad() #Should i move this?\n",
    "        \n",
    "        #Calculate gradient        \n",
    "        loss.backward()\n",
    "        \n",
    "        #Adjust model's weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Output stats\n",
    "        if batch % 64 != 0:\n",
    "            loss, curr = loss.item(), batch * len(X)\n",
    "            print(f\"Loss: {loss:7f} [{curr:>5d}/{size:>5d}]\")  \n",
    "    \n",
    "    #Test Loop\n",
    "    size = len(test_dataloader.dataset)\n",
    "    num_batches= len(test_dataloader)\n",
    "    test_loss, correct = 0,0\n",
    "    \n",
    "    with torch.no_grad(): #turns off gradient calculation\n",
    "        for X, y in test_dataloader:\n",
    "            pred= base_model(X.float())\n",
    "            test_loss += criterion(pred, y.flatten()).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Accuracy:\\nAccuracy: {(100*correct)/size:>.01f}%, Avg loss: {test_loss:>5f}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99860e1c-1c7b-46cb-91dd-7832a0ef28d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06936a34-c60e-473a-a5e2-58f2af6e0dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for batch, (X,y) in enumerate(train_dataloader):\n",
    "    print(batch)\n",
    "    print(X)\n",
    "    print(y)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1fc79a-b4bc-4e7a-a272-a1f1fc3d304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.flatten().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64386f1c-988e-4018-a07d-f8d5f08e5dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec38258-d3f2-4035-8c2a-dc28c66aa61d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc026a-2b6b-4886-aa9a-18f7fbf864c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
