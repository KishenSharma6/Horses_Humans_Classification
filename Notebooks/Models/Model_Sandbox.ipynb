{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d778183-abda-4d03-b931-c1753afe157c",
   "metadata": {},
   "source": [
    "Import Libraries/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e11bac-827e-4653-9302-9f643dee2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "\n",
    "#Import image loaders\n",
    "os.chdir(\"../../src/\")\n",
    "from load_data import preview_images, load_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bf8754b-adbd-4c80-b9ce-8e556e9735b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Horse Data: (500, 300, 300, 4) \n",
      "Test Horse Data: (128, 300, 300, 4)\n",
      "\n",
      "Training Human Data: (527, 300, 300, 4) \n",
      "Test Human Data: (128, 300, 300, 4)\n"
     ]
    }
   ],
   "source": [
    "#Import and preview image data\n",
    "train_path= \"../Data/train/\"\n",
    "horse_train= load_images(train_path + \"horses/\")\n",
    "human_train= load_images(train_path + \"humans/\")\n",
    "\n",
    "val_path= \"../Data/validation/\"\n",
    "horse_test= load_images(val_path + \"horses/\")\n",
    "human_test= load_images(val_path + \"humans/\")\n",
    "\n",
    "#Sanity Check\n",
    "print(\"Training Horse Data: %s \\nTest Horse Data: %s\\n\" % (horse_train.shape, horse_test.shape))\n",
    "print(\"Training Human Data: %s \\nTest Human Data: %s\" % (human_train.shape, human_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ca338-5399-42eb-afc1-606c57a7d3d7",
   "metadata": {},
   "source": [
    "Preprocess **Training** Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50acbea2-ea42-46d2-ac95-a35c7b803c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: torch.Size([1027, 300, 300, 4])\n",
      "Data type: <class 'torch.Tensor'> \n",
      "Training label shape: torch.Size([1027, 1])\n",
      "Data type: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "#Assign labels: 1= human, 0 = horse\n",
    "y_train_human= np.full((len(human_train),1), 1)\n",
    "y_train_horse= np.full((len(horse_train),1), 0)\n",
    "\n",
    "#Concatenate Training data\n",
    "X= np.concatenate((horse_train, human_train), axis=0)\n",
    "y= np.concatenate((y_train_horse, y_train_human), axis= 0)\n",
    "\n",
    "#Zero-center data\n",
    "training_mean= X.mean()\n",
    "training_std= X.std()\n",
    "X= (X - training_mean)/training_std\n",
    "\n",
    "#Shuffle and convert to tensors\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train= shuffle(X, y)\n",
    "\n",
    "X_train= torch.from_numpy(X_train)\n",
    "y_train= torch.from_numpy(y_train)\n",
    "\n",
    "#Sanity check\n",
    "print(\"Training data shape: %s\\nData type: %s \\nTraining label shape: %s\\nData type: %s\" % (X_train.shape,\n",
    "                                                                                              type(X_train),\n",
    "                                                                                              y_train.shape,\n",
    "                                                                                              type(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a076f7c3-1ccd-4a50-af7b-25ae1a07c4dc",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192f8c3c-4b86-432a-bf51-222b970e8381",
   "metadata": {},
   "source": [
    "Base ANN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85a65ffd-3144-43fc-a9ce-73c3242740e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseNeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=360000, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Use base model from early computer vision\n",
    "from models import BaseNeuralNetwork\n",
    "\n",
    "device= \"cpu\"\n",
    "base_model= BaseNeuralNetwork().to(device)\n",
    "print(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9da65b-1f9f-428c-b28f-bcd6ff2e8031",
   "metadata": {},
   "source": [
    "Base ANN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cf8cc48-9b61-40ff-a734-bdf84dedb5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "#Set up loss function, optimizer and batch\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(base_model.parameters(),\n",
    "                      lr= 10 ** -3,\n",
    "                       momentum= .9)\n",
    "\n",
    "batch_size= 32\n",
    "#data loader allows for batching and provides iterable over dataset\n",
    "train_loader= DataLoader(X_train,\n",
    "                                         batch_size,\n",
    "                                         shuffle= True)\n",
    "\n",
    "\n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4cbc101-094b-49ef-9790-7827dc19675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4432ff2-69c3-48d3-847c-8e35ad5ae7f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yv/nkm_y3rj0bj50pcbjh23kfd80000gn/T/ipykernel_6318/2808485687.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get some random training images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc5a989-73ae-4306-a37d-35f5ac4ce855",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f8df2ca-b76a-4ecf-8802-c746f6ec500e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5082d098-af79-43c9-8698-a015ddb1bbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "adfadfafaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f84374-fca2-4036-b7a1-07f2fa47a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch, labels_batch = next(iter(train_loader)), next(iter(train_loader))\n",
    "print(data_batch.size())\n",
    "\n",
    "\n",
    "print(labels_batch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c1a155-47e2-4c06-9703-e741b9769fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size= len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y= X.to(device), y.to(device)\n",
    "        #Compute prediction error\n",
    "        pred= model(X)\n",
    "        loss= loss_fn(pred, y)\n",
    "        #Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current= loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4f0e39-6231-470d-946a-c696e56652c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs= 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    epoch_loss= 0.0\n",
    "    \n",
    "for batch_size, (X_train, y_train) in enumerate(train_loader):\n",
    "    \n",
    "    optimizer.zero_grad() #sets gradient to 0\n",
    "    \n",
    "    preds = base_model(X_train) #perform forward pass\n",
    "    loss = criterion(preds, y_train) #calculate loss from preds from ground truth\n",
    "    loss.backward()\n",
    "#    print(\"Training Epoch:%s\\n--------------------------------------\" % (e + 1))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab79768-866c-48e9-abf6-b3681c74cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dont run below this line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e86b3-0157-43fb-8f5d-ffe44ed66dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f993075-97e0-4d44-9ee8-cdc87a6a825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits= base_model(X.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a5cfb-573f-42de-8ef3-121619897f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790ff088-4bf7-4489-bc29-80c648e969ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs= torch.nn.Softmax(dim= 1)(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3d7f4a-0f7e-43b0-a897-ea8151b3be21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred_probs.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9b8559-21f6-4843-a172-f48d795227b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating accuracy between predictions and truth\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686739f8-bd15-42ef-9d5a-fd9b3572c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTorch CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd971727-cf0c-4643-89bf-5531f900f0e6",
   "metadata": {},
   "source": [
    "**Deploy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ecce23-84f9-40fd-ae70-434b773a7c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_human= np.full((len(human_test),1), 1)\n",
    "# y_test_horse= np.full((len(horse_test),1), 0)\n",
    "\n",
    "# #Concatenate validation set\n",
    "# X= np.concatenate((horse_test, human_test), axis=0)\n",
    "# y= np.concatenate((y_test_horse, y_test_human), axis= 0)\n",
    "\n",
    "# #Zero-Center data\n",
    "# X= (X- training_mean)/training_std\n",
    "\n",
    "# #Shuffle\n",
    "# X_test, y_test= shuffle(X, y)\n",
    "\n",
    "# #Sanity check\n",
    "# print(\"Test data shape: %s \\n Training label shape: %s\" % (X_test.shape, y_test.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
